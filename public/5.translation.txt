Веб-семантика в облаках

За последние два года количество структурированных данных, доступных в Интернете в семантических форматах, выросло на несколько порядков. С одной стороны, проект Linked Data предоставил онлайн сотни миллионов описаний сущностей на основе Resource Description Framework (RDF) в наборах данных, таких как DBPedia, Uniprot и Geonames. С другой стороны, сообщество Web 2-0 все больше принимает идею переносимости данных, и первые усилия уже привели к созданию миллиардов RDF-эквивалентных троек, встроенных в HTML-страницы с использованием микроформатов или представленных напрямую с помощью eRDF (embedded RDF) и RDFa (RDF attributes).

Мотивы для публикации таких данных также становятся все более ясными. Например, Yahoo’s SearchMonkey выделяет сайты, содержащие структурированные данные, предоставляя наиболее подходящую визуализацию для конечного пользователя на странице результатов поиска. Мы ожидаем, что в скором времени поисковые системы также будут использовать эту информацию для целей ранжирования и определения релевантности — например, выдавая качественно лучшие результаты по запросам, связанным с повседневными сущностями, такими как события, местоположения и люди.

Несмотря на то что мы все еще находимся в начале эры веб-данных, уже доступное количество информации явно гораздо больше, чем может содержать, например, любое современное хранилище троек (база данных для хранения и извлечения RDF метаданных), обычно работающее на одном сервере.

Хотя многим приложениям потребуется работать с большими объемами метаданных, одно конкретное приложение не существовало бы без возможности доступа и обработки произвольных объемов метаданных: поисковые системы, которые находят данные и сервисы, необходимые другим приложениям. По этой причине поисковые системы Семантической сети и крупномасштабные сервисы первыми используют мощь грид-вычислений для масштабирования далеко за пределы текущего поколения хранилищ троек.

Облачные вычисления для веб-данных

Не все вычислительно-интенсивные задачи требуют одинаково структурированных аппаратных конфигураций. Классические суперкомпьютеры, обычно характеризующиеся превосходной производительностью в арифметике на один процессор и высококлассными технологиями межпроцессорного соединения, являются проверенными инструментами, которые добились больших успехов в физике, астрономии, химии, биологии и многих других областях. В общем, исследователям трудно превзойти такие высококлассные машины, когда они сталкиваются с задачами, которые трудно распараллелить, или когда требуется интенсивная межпроцессорная коммуникация.

Однако, когда это не так, кластерные вычислительные подходы обычно демонстрируют гораздо большую гибкость в использовании ресурсов и значительно меньшие общие затраты. В крайнем случае облака могут охватить весь Интернет: вычисления, включающие относительно небольшие блоки данных, без необходимости координации и без значительных ограничений по времени выполнения, проводились по всему Интернету — например, используя свободные циклы настольных компьютеров, как в проектах SETI или Folding@home.

Вычисления, необходимые для обработки веб-данных, находятся где-то между этими крайностями. С одной стороны, веб-данные взаимосвязаны, и анализ их сетки оказался фундаментальным для получения понимания их скрытой природы. В то же время, однако, данные по своей природе распределены и могут считаться согласованными с собой, если вообще могут, только в пределах одного веб-сайта. Более того, заметной характеристикой является огромное количество таких данных, где петабайт является обычным порядком величины.

Для обработки такого рода данных ведущие интернет-поисковые системы первыми начали разрабатывать способы выполнения крупномасштабных вычислений веб-данных на кластерах обычных машин, соединенных с использованием стандартных сетевых технологий. Публикации Google о его фреймворке MapReduce и более недавно инициированная Yahoo открытая реализация Hadoop привлекают все больше внимания как разработчиков, так и пользователей.

Стиль вычислений MapReduce хорошо сочетается с возможностями, предлагаемыми развивающейся парадигмой облачных вычислений. Этот стиль вычислений предоставляет полезные абстракции, позволяющие разработчикам сосредоточиться на выполняемой задаче (см боковую панель "Подробнее об этих технологиях"). Выполнение вычислений "в облаках" относится к модели, в которой приложение запрашивает вычислительные ресурсы у поставщика услуг, не беспокоясь о деталях предложения. Примером, который недавно стал популярным, является предложение Amazon Elastic Computing, которое позволяет выделять вычислительные мощности за считанные минуты и динамически увеличивать их по мере необходимости, например, чтобы быстро справиться с неожиданным наплывом посетителей. Поскольку MapReduce не зависит от фактического размера кластера, на котором он выполняется, выполнение Hadoop на таких облакоподобных инфраструктурах является привлекательной стратегией для выполнения вычислительно-интенсивных задач, минимизируя или оптимизируя начальные инвестиции в инфраструктуру. Сочетанная парадигма обычно называется масштабируемыми вычислениями с интенсивным использованием данных (DISC).

В отношении сложных задач, связанных с обработкой веб-данных, подход DISC по многим причинам является естественным выбором. С одной стороны, многие задачи, такие как обход, могут выполняться аналогично обработке обычного веб-контента (HTML-страниц). Часто требуется специальное обращение и специализированный интеллект для семантического обхода данных, но в целом он не сильно отличается от обхода HTML-веба. Аналогично, ранжирование источника Семантической сети, такого как сайты или наборы данных, на основе алгоритмов, подобных PageRank, и, следовательно, эффективно рассчитываемое с использованием MapReduce, было предложено. С другой стороны, для специально решения проблем веб-данных требуются многие другие вычислительно-интенсивные задачи пакетной обработки. Примеры включают анализ данных в крупном масштабе, очистку, рассуждение, распознавание и консолидацию сущностей и сопоставление онтологий.

Грид-вычисления, безусловно, полезны в некоторых из этих задач. Сначала мы покажем, как Yahoo использует грид-вычисления с использованием Hadoop для анализа, преобразования и запросов больших объемов RDF-данных в режиме пакетной обработки, используя кластеры из сотен машин без явных узких мест в масштабируемости. Далее мы покажем, как поисковая система Семантической сети Sindice использует Hadoop и связанные технологии для масштабирования семантической индексации за пределы ограничений специализированных кластерных сред, снижая при этом затраты и сложность.

Пакетная обработка RDF с использованием Yahoo Pig

Yahoo использует грид-вычисления с использованием Hadoop для анализа, преобразования и запросов больших объемов RDF-данных в режиме пакетной обработки, используя кластеры из сотен машин без явных узких мест в масштабируемости. Поисковый робот Yahoo, любовно названный Slurp, начал индексировать содержимое микроформатов весной этого года, и компания недавно добавила eRDF и RDFa к своим поддерживаемым форматам. Yahoo также внес инновации в область Семантической сети, позволяя владельцам сайтов публиковать метаданные с использованием формата DataRSS, основанного на Atom формата для доставки RDF-данных. Платформа приложений Yahoo SearchMonkey, вероятно, приведет к дальнейшему взрыву объема обрабатываемых данных. Разработчики SearchMonkey могут создавать так называемые пользовательские службы данных для извлечения метаданных из существующих веб-сайтов или превращения API в источники метаданных. Все собранные Yahoo метаданные хранятся в формате, совместимом с RDF, поэтому для их обработки требуется возможность запросов и преобразования больших объемов RDF-данных.

Yahoo стремится разработать решения для данных, которые решают широкий круг задач управления данными и которые могут легко адаптироваться к новым задачам, таким как задача, поставленная SearchMonkey. Один из этих инструментов, Yahoo Pig, упрощает обработку больших наборов данных на компьютерных кластерах, применяя концепции из параллельных баз данных. Изначально он был разработан в исследовательском подразделении Yahoo, но недавно был предоставлен в открытый доступ под лицензией Apache 2-0. Pig предоставляет нативную поддержку для преобразований данных, таких как проекции, группировка, сортировка, соединение и композиции. Выразительность языка преобразования Pig примерно эквивалентна стандартной реляционной алгебре (которая также составляет основу SQL), с дополнительным преимуществом расширяемости через пользовательские функции, написанные на Java. Программисты Pig разрабатывают пользовательский код для загрузки и сохранения данных в других форматах в модель данных Pig, которая снова строится на реляционной модели (мешки кортежей) с дополнительными функциями, такими как карты и вложенные мешки кортежей. Сценарии, написанные на PigLatin, родном языке Pig, выполняются на кластере с использованием фреймворка Hadoop или двигателя обработки кортежей Galago. В отличие от HBase, Pig на самом деле не можно назвать базой данных: обработка осуществляется путем итерации через весь набор данных (данные не индексируются и не могут быть обновлены), а результаты вычислений сохраняются. Однако HBase не предлагает язык запросов, только извлечение кортежей по их индексу.

Мы заметили, что модель данных Pig и язык преобразования аналогичны реляционным представлениям RDF и языку запросов Sparql, соответственно, поэтому мы недавно расширили Pig для выполнения запросов и преобразований RDF. В рамках этой работы мы реализовали функции загрузки и сохранения для преобразования RDF в модель данных Pig, создали сопоставление между Sparql и PigLatin и доказали, что это сопоставление полное.
